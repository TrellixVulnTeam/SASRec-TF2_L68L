{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Knowledge Graph from Amazon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/recsys_data/RecSys/recommenders/tests/resources/deeprec/slirec\"\n",
    "filename = 'meta_Electronics.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498196\n"
     ]
    }
   ],
   "source": [
    "all_keys = set()\n",
    "all_vals = []\n",
    "entity_dict = dict()\n",
    "category_dict = dict()\n",
    "count = 0\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "\n",
    "#         jstr = line.strip()\n",
    "#         jstr = re.sub(r\"[0-9]\\\"\", \"\", jstr)\n",
    "#         jstr = re.sub(r\"[^:]\\s\\\"\\w|\\w\\\" \", \" \", jstr)    \n",
    "#         jstr = jstr.replace(\"\\'\", \"\\\"\")\n",
    "#         jdict = json.loads(jstr)\n",
    "        keys = jdict.keys()\n",
    "        all_keys.update(keys)\n",
    "        all_vals.append(jdict)\n",
    "        entity_dict[jdict['asin']] = {'id': count}\n",
    "        if 'related' in jdict:\n",
    "            entity_dict[jdict['asin']]['related'] = jdict['related']\n",
    "        for cat in jdict['categories'][0]:\n",
    "            if cat not in category_dict:\n",
    "                category_dict[cat] = []\n",
    "            category_dict[cat].append(jdict['asin'])\n",
    "#         entity_dict[jdict['asin']]['categories'] = jdict['categories']\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cat in category_dict:\n",
    "#     ratio = len(category_dict[cat])/count\n",
    "#     if ratio > 0.1:\n",
    "#         print(cat, len(category_dict[cat]), ratio)\n",
    "        \n",
    "# for cat in category_dict:\n",
    "#     if 10 < len(category_dict[cat]) < 100:\n",
    "#         print(cat, len(category_dict[cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_files(out_dir, categories, entities, max_examples=None):\n",
    "    include_categories = []\n",
    "    for cat in categories:\n",
    "        ratio = len(categories[cat])/count\n",
    "#         if ratio > cutoff and ratio < 0.8:\n",
    "        if 10 < len(category_dict[cat]) < 100:\n",
    "            include_categories.append(cat)\n",
    "    \n",
    "    relations = copy.deepcopy(include_categories)\n",
    "    include_categories.extend(['also_viewed', 'buy_after_viewing'])\n",
    "    print(f\"Added {len(include_categories)} relations\")\n",
    "        \n",
    "    # entity2id.txt\n",
    "    with open(os.path.join(out_dir, 'AE', 'entity2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(entities)) + '\\n')\n",
    "        for e in entities:\n",
    "            fw.write(e + '\\t' + str(entities[e]['id']) + '\\n')\n",
    "    \n",
    "    # relation2id.txt\n",
    "    with open(os.path.join(out_dir, 'AE', 'relation2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(include_categories)) + '\\n')\n",
    "        for ii, r in enumerate(include_categories):\n",
    "            fw.write(r + '\\t' + str(ii) + '\\n')\n",
    "    \n",
    "    # train2id.txt\n",
    "    train, valid, test = [], [], []\n",
    "    count_train, count_valid, count_test = 0, 0, 0\n",
    "\n",
    "    for jj, cat in enumerate(relations):\n",
    "        similar_entities = categories[cat]\n",
    "        print(cat, len(similar_entities))\n",
    "        for e1 in similar_entities:\n",
    "            for e2 in similar_entities:\n",
    "                if e1 != e2:\n",
    "                    tuples = (entities[e1]['id'], entities[e2]['id'], jj)\n",
    "                    rnd = random.random()\n",
    "                    if rnd <= 0.7:\n",
    "                        train.append(tuples)\n",
    "                        count_train += 1\n",
    "                    elif rnd <= 0.85:\n",
    "                        valid.append(tuples)\n",
    "                        count_valid += 1\n",
    "                    else:\n",
    "                        test.append(tuples)\n",
    "                        count_test += 1\n",
    "    \n",
    "    print(f\"Train: {count_train}, Validation: {count_valid} and Test: {count_test}\")\n",
    "    \n",
    "    for e in entities:\n",
    "        if 'related' in entities[e]:\n",
    "            if 'also_viewed' in entities[e]['related']:\n",
    "                connected = entities[e]['related']['also_viewed']\n",
    "                jj = include_categories.index('also_viewed')\n",
    "                for e2 in connected:\n",
    "                    if e2 in entities:\n",
    "                        tuples = (entities[e]['id'], entities[e2]['id'], jj)\n",
    "                        rnd = random.random()\n",
    "                        if rnd <= 0.7:\n",
    "                            train.append(tuples)\n",
    "                            count_train += 1\n",
    "                        elif rnd <= 0.85:\n",
    "                            valid.append(tuples)\n",
    "                            count_valid += 1\n",
    "                        else:\n",
    "                            test.append(tuples)\n",
    "                            count_test += 1\n",
    "                            \n",
    "            if 'buy_after_viewing' in entities[e]['related']:\n",
    "                connected = entities[e]['related']['buy_after_viewing']\n",
    "                jj = include_categories.index('buy_after_viewing')\n",
    "                for e2 in connected:\n",
    "                    if e2 in entities:\n",
    "                        tuples = (entities[e]['id'], entities[e2]['id'], jj)\n",
    "                        rnd = random.random()\n",
    "                        if rnd <= 0.7:\n",
    "                            train.append(tuples)\n",
    "                            count_train += 1\n",
    "                        elif rnd <= 0.85:\n",
    "                            valid.append(tuples)\n",
    "                            count_valid += 1\n",
    "                        else:\n",
    "                            test.append(tuples)\n",
    "                            count_test += 1\n",
    "    \n",
    "    print(f\"Train: {count_train}, Validation: {count_valid} and Test: {count_test}\")\n",
    "    \n",
    "    random.shuffle(train)\n",
    "    random.shuffle(valid)\n",
    "    random.shuffle(test)\n",
    "    \n",
    "    if max_examples:\n",
    "        train = train[:max_examples]\n",
    "        valid = valid[:max_examples]\n",
    "        test = test[:max_examples]\n",
    "    \n",
    "    with open(os.path.join(out_dir, 'AE', 'train2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(train)) + '\\n')\n",
    "        for tup in train:\n",
    "            out = [str(e) for e in tup]\n",
    "            fw.write(' '.join(out) + '\\n')\n",
    "        \n",
    "    with open(os.path.join(out_dir, 'AE', 'valid2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(valid)) + '\\n')\n",
    "        for tup in valid:\n",
    "            out = [str(e) for e in tup]\n",
    "            fw.write(' '.join(out) + '\\n')\n",
    "        \n",
    "    with open(os.path.join(out_dir, 'AE', 'test2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(test)) + '\\n')\n",
    "        for tup in test:\n",
    "            out = [str(e) for e in tup]\n",
    "            fw.write(' '.join(out) + '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 219 relations\n",
      "Stylus Pens 63\n",
      "USB Fans 91\n",
      "VHS 72\n",
      "Hi-8 45\n",
      "Color Correction & Compensation Filters 94\n",
      "APS Cameras 59\n",
      "VHS-C 23\n",
      "Systems 24\n",
      "Wireless Jack Systems 25\n",
      "VCR Rewinders 32\n",
      "Caller ID Displays 89\n",
      "Cable Straps 64\n",
      "PS/2 Cables 50\n",
      "SCSI Cables 57\n",
      "Zip Discs 45\n",
      "Minidisc Players 51\n",
      "External Zip Drives 52\n",
      "Internal Modems 84\n",
      "Tape Decks 57\n",
      "Minidiscs 32\n",
      "Security Locks 72\n",
      "Automotive 44\n",
      "CD Recorders 55\n",
      "Tuners 95\n",
      "CD-RW Discs 77\n",
      "SmartMedia Cards 36\n",
      "Radar Systems 14\n",
      "Changers 46\n",
      "Handheld CB Radios 11\n",
      "Catadioptric 84\n",
      "Barlow Lenses 29\n",
      "Telescope Cases 36\n",
      "Photo Adapters 27\n",
      "Tape Libraries 19\n",
      "Multimedia Cards 48\n",
      "Parallel Port Cards 59\n",
      "DVD-RAM Discs 53\n",
      "Bluetooth Headsets 99\n",
      "Holsters & Clips 24\n",
      "VTR Decks 17\n",
      "Cassette Storage 21\n",
      "Projectors 36\n",
      "Slide Projectors 35\n",
      "Single-Use Cameras 99\n",
      "Presentation Supplies 32\n",
      "Binding Machine Supplies 13\n",
      "Calculator Accessories 93\n",
      "Tabletop & Travel Tripods 22\n",
      "TV Turntables 44\n",
      "Port Tubes 22\n",
      "Dew Caps 37\n",
      "Fixed-mount CB Radios 74\n",
      "Binocular Accessories 56\n",
      "Clock Radios 61\n",
      "Mounting Accessories 87\n",
      "Satellite Finders 55\n",
      "DLT Cleaning Cartridges 39\n",
      "Overhead Supplies 18\n",
      "Graduated Color Filters 65\n",
      "Brushes 45\n",
      "Step-Up Rings 96\n",
      "Distribution Panels 92\n",
      "Line Conditioners 72\n",
      "Parallel Adapters 25\n",
      "Film Processing Equipment 55\n",
      "Projector Bags & Cases 45\n",
      "Projector Cases 33\n",
      "Speaker Accessories 47\n",
      "Stereo Microscopes 58\n",
      "Phone Cards 30\n",
      "Satellite Dishes 40\n",
      "Rangefinder Cameras 19\n",
      "RF Modulators 79\n",
      "DVD+RW Discs 71\n",
      "Barn Doors 30\n",
      "External TV Tuners 77\n",
      "Hi-Fi & HT Cabinets 90\n",
      "Firewire Adapters 18\n",
      "Crossover Parts 73\n",
      "Cables 24\n",
      "Grills 90\n",
      "Finder Scopes 35\n",
      "DATs 18\n",
      "USB-to-VGA Adapters 98\n",
      "Cable Raceways 50\n",
      "Computer Vacuums 69\n",
      "Device Servers 22\n",
      "MiniSD Cards 69\n",
      "Warranties & Services 71\n",
      "Computer Equipment Warranties 67\n",
      "USB Lamps 88\n",
      "Video Multiplexers & Quads 21\n",
      "Biometrics 75\n",
      "Cell Phones 20\n",
      "TV Tuners 38\n",
      "Compressed Air 16\n",
      "Surface-mounted Speakers 19\n",
      "Tweeter Diaphragms 48\n",
      "Slide, Negative & Print Pages 72\n",
      "Photo Enlarging Paper 68\n",
      "Monopod Heads 65\n",
      "Chemicals 60\n",
      "Diopters 54\n",
      "Filter Cases 22\n",
      "Light Boxes & Loupes 52\n",
      "Loupes 51\n",
      "Archival Storage Binders 16\n",
      "Safelights 41\n",
      "Binocular Cases 12\n",
      "Tripod & Monopod Cases 48\n",
      "Flash Tubes 23\n",
      "Grey Cards 36\n",
      "Slaves 55\n",
      "Medium & Large-Format Cameras 36\n",
      "Diagonals 13\n",
      "Copying Equipment 18\n",
      "Guiders & Wedges 14\n",
      "Printers & Scanners 52\n",
      "Portable Photo Printers 52\n",
      "Center Columns 17\n",
      "Marine Antennas 91\n",
      "Opera Glasses 55\n",
      "External Sound Cards 48\n",
      "Tools & Equipment 31\n",
      "Mounting Kits 78\n",
      "Liquid Cleaners 15\n",
      "Voice Dialers 33\n",
      "Horns & Sirens 87\n",
      "Step-Down Rings 24\n",
      "Subwoofer Amplifiers 41\n",
      "Aircraft Accessories 67\n",
      "Marine Speakers 11\n",
      "Cable Sleeves 98\n",
      "Enclosed Subwoofer Systems 30\n",
      "Speaker Grills 94\n",
      "Signal Boosters 36\n",
      "Feet & Spikes 36\n",
      "Dust Caps 66\n",
      "Handles 29\n",
      "Case Hardware & Latches 15\n",
      "Home Audio Crossovers & Parts 27\n",
      "Video Transmission Systems 68\n",
      "Connecting Blocks 31\n",
      "Power Packs 15\n",
      "Carpet & Vinyl 28\n",
      "Handheld Digital Photo Viewers 40\n",
      "Service & Replacement Plans 90\n",
      "Service Plans 80\n",
      "Line Cords 32\n",
      "Barking-Dog Alarms 11\n",
      "GPS Trackers 49\n",
      "Headsets & Intercoms 85\n",
      "Surveillance Camera Lenses 71\n",
      "Cycling GPS Units 56\n",
      "Charging Stations 30\n",
      "Component Speakers 15\n",
      "Internal Batteries 95\n",
      "Data Cables 79\n",
      "Motorcycle GPS 29\n",
      "Traffic Message Channel (TMC) Receiver Modules 29\n",
      "Shooting Tables 35\n",
      "Specialty Film Cameras 19\n",
      "Replacement Parts 11\n",
      "Aviation GPS 38\n",
      "Travel Chargers 51\n",
      "Professional Video Cameras 60\n",
      "Car Accessories 60\n",
      "BD-RE Discs 72\n",
      "Floor Cord Covers 80\n",
      "Mini-SAS Cables 26\n",
      "Hard Drive Cases 15\n",
      "Continuous Output Lighting 65\n",
      "HDD Cooling Fans 19\n",
      "Autopilots 22\n",
      "Tripod Mount Rings 46\n",
      "Video Studio 51\n",
      "External Battery Packs 84\n",
      "Video Monitors 37\n",
      "Follow-Focus Levers 52\n",
      "Camera & Camcorder Lens Bundles 86\n",
      "Solar Chargers 45\n",
      "Car Cradles & Mounts 45\n",
      "Car Mounts 40\n",
      "SCSI Adapters 22\n",
      "Graphics Card Fans 26\n",
      "Car Care 24\n",
      "Cloths & Towels 24\n",
      "Chamois 24\n",
      "Matte Boxes 22\n",
      "Aircraft Avionics 17\n",
      "Bluetooth Speakers 86\n",
      "Sandbags 31\n",
      "Motorcycle Accessory Mounts 26\n",
      "Camera Cine Dollies 12\n",
      "Camera Cranes 28\n",
      "IR Illuminators 11\n",
      "Lens Supports 38\n",
      "Laptop Barebones 21\n",
      "External Solid State Drives 61\n",
      "Motorcycle Bluetooth Headsets 43\n",
      "Aviation Handheld Radios 19\n",
      "Color Calibration Charts 20\n",
      "Cell Phone Docks 12\n",
      "Vehicle Tracking and Monitoring Modules 71\n",
      "Installation Services 76\n",
      "Kick-Panel Enclosures 27\n",
      "Compact System Camera Lenses 59\n",
      "Satellite Dish Mounts 17\n",
      "Connected Devices 12\n",
      "Lightning Cables 80\n",
      "Digital Handwriting Pads 13\n",
      "Thunderbolt Cables 20\n",
      "In-Mirror Video 21\n",
      "Compact System Camera Bundles 22\n",
      "Speaker Repair Accessories 18\n",
      "USB Beverage Warmers 18\n",
      "Microscope Accessories 26\n",
      "Train: 407065, Validation: 87246 and Test: 86995\n",
      "Train: 3251152, Validation: 697295 and Test: 696633\n"
     ]
    }
   ],
   "source": [
    "write_all_files(out_dir='/recsys_data/RecSys/OpenKE/benchmarks/',\n",
    "                categories=category_dict,\n",
    "                entities=entity_dict,\n",
    "                max_examples=10000\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0545016266' in entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 498195,\n",
       " 'related': {'also_viewed': ['B0007T27H8', 'B00425S1H8', 'B000BI95W0'],\n",
       "  'buy_after_viewing': ['B0007T27H8', 'B00425S1H8']}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict['BT008T2BGK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38726\n"
     ]
    }
   ],
   "source": [
    "desc_dict = dict()\n",
    "count_missing = 0\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if 'description' not in jdict:\n",
    "            count_missing += 1\n",
    "        else:\n",
    "            desc_dict[jdict['asin']] = jdict['description']\n",
    "print(count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "img_dict = dict()\n",
    "count_missing = 0\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if 'imUrl' not in jdict:\n",
    "            count_missing += 1\n",
    "        else:\n",
    "            img_dict[jdict['asin']] = jdict['imUrl']\n",
    "print(count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size: 2.87(W) x 8.(L) x 1.12(D)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "ss = 'Size: 2.875\"(W) x 8.5\"(L) x 1.125\"(D)'\n",
    "# ss.replace(r\"[0-9]\\\"\", '')\n",
    "re.sub(r\"[0-9]\\\"\", \"\", ss)\n",
    "\n",
    "#\n",
    "ss = '\"key\": \"HDTV\" accented by a subtle \"nook\" logo'\n",
    "re.sub(r\"[^:]\\s\\\"\\w|\\w\\\" \", \" \", ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_with_time(fname, pname, sep=\"\\t\", file_write=False):\n",
    "    User = defaultdict(list)\n",
    "    Items = set()\n",
    "    user_dict, item_dict = {}, {}\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        for line in fr:\n",
    "            u, i, t = line.rstrip().split(sep)\n",
    "            User[u].append((i, t))\n",
    "            Items.add(i)\n",
    "    \n",
    "    print(len(User), len(Items))\n",
    "    item_count = 1\n",
    "    for item in Items:\n",
    "        item_dict[item] = item_count\n",
    "        item_count += 1\n",
    "\n",
    "    count_del = 0\n",
    "    user_count = 1\n",
    "    if file_write:\n",
    "        with open(pname, 'w') as fw:\n",
    "            for user in User.keys():\n",
    "                if len(User[user]) <= 2:\n",
    "                    del User[user]\n",
    "                    count_del += 1\n",
    "                else:\n",
    "                    # user_dict[user] = user_count\n",
    "                    items = sorted(User[user], key=lambda x: x[1])\n",
    "                    items = [item_dict[x[0]] for x in items]\n",
    "                    for item in items:\n",
    "                        fw.write(str(user_count) + ' ' + str(item) + '\\n')\n",
    "                    user_count += 1\n",
    "    else:\n",
    "        for user in User.keys():\n",
    "            if len(User[user]) <= 2:\n",
    "                # del User[user]\n",
    "                count_del += 1\n",
    "            else:\n",
    "                user_dict[user] = user_count\n",
    "                user_count += 1\n",
    "        \n",
    "    print(user_count-1, count_del)\n",
    "    return user_dict, item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63161 85930\n",
      "63114 47\n"
     ]
    }
   ],
   "source": [
    "udict, idict = data_process_with_time(\"/recsys_data/RecSys/SASRec-tf2/data/ae_original.txt\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63114, 85930)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(udict), len(idict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_udict = {v:k for k, v in udict.items()}\n",
    "inv_idict = {v:k for k, v in idict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B0013J5XZE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 95536,\n",
       " 'related': {'also_bought': ['B000XB9GV0',\n",
       "   'B003HFB9B4',\n",
       "   'B003U8YAWI',\n",
       "   'B0028ZCXQ4',\n",
       "   'B000XB9GUG',\n",
       "   'B00494P6AW',\n",
       "   'B006LZQ6O2',\n",
       "   'B000XB4412',\n",
       "   'B001ENW61I',\n",
       "   'B00009UTL1',\n",
       "   '032171105X',\n",
       "   'B004BFZHO4',\n",
       "   'B003HF3A34',\n",
       "   'B003UOIMAS',\n",
       "   'B00452V288',\n",
       "   'B001M4HXB2',\n",
       "   'B0009BX0AM',\n",
       "   'B0028ZETAC',\n",
       "   'B0083Z6R4W',\n",
       "   'B00009UTZA',\n",
       "   'B001OKBLEE',\n",
       "   'B004BFXBXI',\n",
       "   'B001HAER88',\n",
       "   'B00DNADZME',\n",
       "   'B007FH1KX2',\n",
       "   'B000CLNHXY',\n",
       "   'B003OU51LG',\n",
       "   'B003GR6IUK',\n",
       "   'B0090BSSZO',\n",
       "   'B0007DDK7A',\n",
       "   'B00BXA7N6A',\n",
       "   'B002XUN2AA',\n",
       "   'B003N8SKDU',\n",
       "   'B007FH1LJU',\n",
       "   'B002YWHSVG',\n",
       "   'B003VBO4U2',\n",
       "   'B004YG7JXW',\n",
       "   'B003TYDBYQ',\n",
       "   'B001DIG46M',\n",
       "   'B003CRZFT4',\n",
       "   'B006ISEJ9Q',\n",
       "   '0321832752',\n",
       "   'B00HO0BYQS',\n",
       "   'B001E4LC6C',\n",
       "   '0321580141',\n",
       "   'B005GMWEI8',\n",
       "   'B001M4HTAW',\n",
       "   'B002Z3H36O',\n",
       "   'B004CBTCFC',\n",
       "   'B004YG7JV4',\n",
       "   'B00AA478UQ',\n",
       "   'B0034WR19Y',\n",
       "   'B00009UTL9',\n",
       "   'B0079M711S',\n",
       "   'B001TANZ0W',\n",
       "   'B00270VQTK',\n",
       "   'B00BWV72O8',\n",
       "   'B00009UTZJ',\n",
       "   'B003YFITC4',\n",
       "   'B000QDRRIE',\n",
       "   'B00BQ5UO1S',\n",
       "   'B001KELVS0',\n",
       "   'B004UG41XW',\n",
       "   'B003WGNSTE',\n",
       "   'B001CCAISE',\n",
       "   'B003UOIMBW',\n",
       "   'B004TGZ7WM',\n",
       "   'B005IQRMN4',\n",
       "   'B003AM38DG',\n",
       "   'B003Y30334',\n",
       "   'B004G3NW5M',\n",
       "   'B0034WR71G',\n",
       "   'B005RDU60O',\n",
       "   '0321803531',\n",
       "   'B003Y2EOBW',\n",
       "   'B001AHALEC',\n",
       "   'B0018LQVIA',\n",
       "   'B005KEL4BU',\n",
       "   'B00JQ4HZPO',\n",
       "   'B009RPBEEK',\n",
       "   '0321929500',\n",
       "   'B0082IX6MG',\n",
       "   'B0023RRPE2',\n",
       "   'B00F36K5Q0',\n",
       "   'B002SWIOOM',\n",
       "   'B00DCY29G4',\n",
       "   'B005UNPM3M',\n",
       "   'B002ZIMEMW',\n",
       "   'B001M4HTH0',\n",
       "   'B007ODZYRK',\n",
       "   '0240812255',\n",
       "   'B0000A4F05',\n",
       "   'B00551636O',\n",
       "   'B0053NWH14',\n",
       "   'B00GUQJZCW',\n",
       "   '111811289X',\n",
       "   '1608955702',\n",
       "   'B0040IWVBY',\n",
       "   'B0016XIQ1U'],\n",
       "  'bought_together': ['B000XB9GV0', 'B003HFB9B4'],\n",
       "  'buy_after_viewing': ['B000XB9GV0',\n",
       "   'B006LZQ6O2',\n",
       "   'B005KEL4NI',\n",
       "   'B00CYVNX0W']}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict['B0013J5XZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Items with Title & Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85930\n"
     ]
    }
   ],
   "source": [
    "ddict = {}\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if jdict['asin'] in idict:\n",
    "            ddict[jdict['asin']] = {}\n",
    "            if 'title' in jdict.keys():\n",
    "                ddict[jdict['asin']]['title'] = jdict['title']\n",
    "            if 'description' in jdict.keys():\n",
    "                ddict[jdict['asin']]['description'] = jdict['description']\n",
    "\n",
    "print(len(ddict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Honl Photo Professional Color Correction Gel Filter Kit for Photo Speed System',\n",
       " 'description': 'Use Honl Color Correction filters to color correct your strobes for tungsten, fluorescent or cool daylight lighting environments. Use CTO filters to match your flash output to tungsten lights, or simply to give a pleasing warm tone to your portraits. Use Full + Green to match your flash output to fluorescent lights. These superior filters are pre-cut with velcro strips attached so they can be quickly fastened to a Speed Strap (sold separately). Honl Filters can be used in conjunction with Honl Snoots, Gobos and Grids. The usable filter area is 2.5\" x 4\" and can be trimmed to fit individual strobes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict['B0013J5XZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for item in ddict:\n",
    "    if len(ddict[item]) == 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nwords(txt, n):\n",
    "    return ' '.join(txt.split()[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18060\n"
     ]
    }
   ],
   "source": [
    "keep_words = 100\n",
    "max_len = 0\n",
    "with open('/recsys_data/RecSys/SASRec-tf2/data/ae_item_description.txt', 'w') as fw:\n",
    "    for item_number in range(1, 85931):\n",
    "        item_name = inv_idict[item_number]\n",
    "        temp_dict = ddict[item_name]\n",
    "        title, desc = '', ''\n",
    "        if 'title' in temp_dict:\n",
    "            title = temp_dict['title'].replace('\\n', '')\n",
    "        if 'description' in temp_dict:\n",
    "            desc = temp_dict['description'].replace('\\n', '')\n",
    "        otxt = title + ' ' + desc\n",
    "        if len(otxt.split()) > max_len:\n",
    "            max_len = len(otxt.split())\n",
    "        otxt = nwords(otxt, keep_words)\n",
    "        fw.write(otxt + '\\n')\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Items with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85930\n"
     ]
    }
   ],
   "source": [
    "imgdict = {}\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if jdict['asin'] in idict:\n",
    "            imgdict[jdict['asin']] = {}\n",
    "            if 'imUrl' in jdict.keys():\n",
    "                imgdict[jdict['asin']]['imUrl'] = jdict['imUrl']\n",
    "\n",
    "print(len(imgdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# Items with no image information\n",
    "count = 0\n",
    "for item in imgdict:\n",
    "    if len(imgdict[item]) == 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imUrl': 'http://ecx.images-amazon.com/images/I/2135RN5gz3L.jpg'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgdict['B0013J5XZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "import urllib\n",
    "\n",
    "item_name = 'B0013J5XZE'\n",
    "imgUrl = imgdict[item_name]['imUrl']\n",
    "imgData = urllib.request.urlopen(imgUrl).read()\n",
    "fileName = item_name + '_' + imgUrl.split('/')[-1]\n",
    "print(filename)\n",
    "output = open(fileName,'wb')\n",
    "output.write(imgData)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
