{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Knowledge Graph from Amazon Data\n",
    "\n",
    "The idea is to create a graph where items are nodes, relations amongst the items are edges. The nodes would have features that can come from the textual description (later we can add images) of the items and target labels - that can be taken as the product category. Once we collect these information we can use some of the Graph Convolution Network (GCN) for node classification task that would result in node embeddings as a by-product.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/recsys_data/RecSys/recommenders/tests/resources/deeprec/slirec\"\n",
    "meta_filename = 'meta_Electronics.json'\n",
    "interaction_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_original.txt\"\n",
    "output_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_v2.txt\"\n",
    "dict_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_v2_dict.pkl\"\n",
    "text_embed_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_v2_text_embeddings.pkl\"\n",
    "\n",
    "# word embeddings\n",
    "glove_dir = \"/recsys_data/datasets/glove\"\n",
    "glove_file = \"glove.6B.50d.txt\"\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the relevant Items\n",
    "\n",
    "While there are too many items in the meta data file we do not need all of them. So first we gather all the relevant items by going through the user interaction history (and do some filtering based on the frequency of interactions). We use K-filter where users and items with less than K interactions are filtered *in one pass*. This is different from K-core where items and users are filtered recursively till all of them have at most K-interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_with_time(fname, pname, sep=\"\\t\", file_write=False):\n",
    "    User = defaultdict(list)\n",
    "    Items = set()\n",
    "    user_dict, item_dict = {}, {}\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        for line in fr:\n",
    "            u, i, t = line.rstrip().split(sep)\n",
    "            User[u].append((i, t))\n",
    "            Items.add(i)\n",
    "    \n",
    "    print(len(User), len(Items))\n",
    "    item_count = 1\n",
    "    for item in Items:\n",
    "        item_dict[item] = item_count\n",
    "        item_count += 1\n",
    "\n",
    "    count_del = 0\n",
    "    user_count = 1\n",
    "    if file_write:\n",
    "        print(f\"Writing data in {pname}\")\n",
    "        with open(pname, 'w') as fw:\n",
    "            for user in User.keys():\n",
    "                if len(User[user]) <= 2:\n",
    "#                     del User[user]\n",
    "                    count_del += 1\n",
    "                else:\n",
    "                    # user_dict[user] = user_count\n",
    "                    items = sorted(User[user], key=lambda x: x[1])\n",
    "                    items = [item_dict[x[0]] for x in items]\n",
    "                    for item in items:\n",
    "                        fw.write(str(user_count) + ' ' + str(item) + '\\n')\n",
    "                    user_dict[user] = user_count\n",
    "                    user_count += 1\n",
    "    else:\n",
    "        for user in User.keys():\n",
    "            if len(User[user]) <= 2:\n",
    "                # del User[user]\n",
    "                count_del += 1\n",
    "            else:\n",
    "                User[user] = sorted(User[user], key=lambda x: x[1])\n",
    "                user_dict[user] = user_count\n",
    "                user_count += 1\n",
    "        \n",
    "    print(user_count-1, count_del)\n",
    "    return user_dict, item_dict, User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63161 85930\n",
      "63114 47\n",
      "Retained 63114 users with 85930 items from 63161 users\n"
     ]
    }
   ],
   "source": [
    "write_file = False\n",
    "\n",
    "# udict, idict, user_history = data_process_with_time(interaction_filename, \"\")\n",
    "udict, idict, user_history = data_process_with_time(interaction_filename, output_filename, \"\\t\", write_file)\n",
    "\n",
    "if write_file:\n",
    "    with open(dict_filename, 'wb') as handle:\n",
    "        pickle.dump((udict, idict, user_history), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Retained {len(udict)} users with {len(idict)} items from {len(user_history)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/recsys_data/RecSys/SASRec-tf2/notebooks'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498196/498196 [00:38<00:00, 12803.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85930 85930\n"
     ]
    }
   ],
   "source": [
    "all_keys = set()\n",
    "all_vals = []\n",
    "entity_dict = dict()\n",
    "category_dict = dict()\n",
    "count = 0\n",
    "count_item = 0\n",
    "\n",
    "# Note: item-id starts with 0 \n",
    "with open(os.path.join(data_dir, meta_filename), 'r') as fr:\n",
    "    for line in tqdm(fr.readlines()):\n",
    "        jdict = eval(line)\n",
    "        \n",
    "        # keep items that are present in the user history\n",
    "        # otherwise, the size becomes too big\n",
    "        if jdict['asin'] not in idict:\n",
    "            continue\n",
    "#         jstr = line.strip()\n",
    "#         jstr = re.sub(r\"[0-9]\\\"\", \"\", jstr)\n",
    "#         jstr = re.sub(r\"[^:]\\s\\\"\\w|\\w\\\" \", \" \", jstr)    \n",
    "#         jstr = jstr.replace(\"\\'\", \"\\\"\")\n",
    "#         jdict = json.loads(jstr)\n",
    "        keys = jdict.keys()\n",
    "        all_keys.update(keys)\n",
    "#         entity_dict[jdict['asin']] = {'id': count}\n",
    "#         if 'related' in jdict:\n",
    "#             entity_dict[jdict['asin']]['related'] = jdict['related']\n",
    "#         for cat in jdict['categories'][0]:\n",
    "#             if cat not in category_dict:\n",
    "#                 category_dict[cat] = []\n",
    "#             category_dict[cat].append(jdict['asin'])\n",
    "#         entity_dict[jdict['asin']]['categories'] = jdict['categories']\n",
    "#         if 'categories' in jdict and ('description' in jdict and 'title' in jdict):\n",
    "        jdict['id'] = count_item\n",
    "        all_vals.append(jdict)\n",
    "        count_item += 1\n",
    "        entity_dict[jdict['asin']] = jdict\n",
    "        count += 1\n",
    "print(count, count_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data\n",
    "\n",
    "Note all items may not have description or title to create node features but they should have `categories` information for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin': '0594451647',\n",
       " 'description': \"HDTV Adapter Kit for NOOK HD and NOOK HD+\\nThis handy kit enables you to stream content from your NOOK HD or NOOK HD+ to a high-definition TV, via the included adapter and High Speed HDMI Cable. The kit also includes a pass-through that allows you to charge your NOOK while streaming, so there's no danger of running out of battery power before you're done. (A compatible NOOK Power Kit is required for this function and is not included with the adapter kit.)\",\n",
       " 'title': 'Barnes &amp; Noble HDTV Adapter Kit for NOOK HD and NOOK HD+',\n",
       " 'price': 49.95,\n",
       " 'imUrl': 'http://ecx.images-amazon.com/images/I/51RjSETO23L._SX300_.jpg',\n",
       " 'related': {'also_bought': ['B009L7EEZA',\n",
       "   'B00AGAYQEU',\n",
       "   'B00AGAS6XW',\n",
       "   'B00BN1Q5JA',\n",
       "   'B00AV1UWWY',\n",
       "   'B00CPV9YOU',\n",
       "   '1400699169',\n",
       "   'B00AK2MHEU',\n",
       "   'B00AFYBTSI',\n",
       "   '0594481813',\n",
       "   'B00AAVF0J0',\n",
       "   '0594481902',\n",
       "   'B00E9IAQ1C',\n",
       "   'B00BKOWE6I',\n",
       "   'B00AAKLZ6I',\n",
       "   'B00AAKLUWC',\n",
       "   'B007KZC6R8',\n",
       "   'B00E9IKYKK',\n",
       "   'B009L7E838',\n",
       "   'B00AFXEMCE',\n",
       "   'B00DE8RFZS',\n",
       "   'B00AFXGMN6',\n",
       "   'B00A668GUO',\n",
       "   '1400698987',\n",
       "   'B00AAKLF22',\n",
       "   'B00E3P4892',\n",
       "   'B00AAKLDN8',\n",
       "   'B009L7EGC6',\n",
       "   'B00B20N9XW',\n",
       "   'B00BN1Q63A',\n",
       "   '1400501520',\n",
       "   'B00JQUT7F4',\n",
       "   'B00B8YC13G',\n",
       "   'B00BN1Q7PW',\n",
       "   'B00AFXKID6',\n",
       "   'B007XCINUW',\n",
       "   'B009L7ED3I',\n",
       "   'B00E9ISXPS',\n",
       "   'B00BN1Q5LS',\n",
       "   'B00DSLC024',\n",
       "   '1449359531',\n",
       "   'B009L7EJAK',\n",
       "   'B00C2L6MAW',\n",
       "   'B00BN1Q5ZE',\n",
       "   'B007FN910U',\n",
       "   'B0063W7XJK',\n",
       "   'B009QZH7BU'],\n",
       "  'bought_together': ['B009L7EEZA'],\n",
       "  'buy_after_viewing': ['0594481813',\n",
       "   '0594481902',\n",
       "   'B009L7EEZA',\n",
       "   'B00AK2MHEU']},\n",
       " 'categories': [['Electronics',\n",
       "   'Computers & Accessories',\n",
       "   'Touch Screen Tablet Accessories',\n",
       "   'Chargers & Adapters']],\n",
       " 'id': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vals[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Node Features\n",
    "\n",
    "We use the `title` and `description` of each item and convert them to a fixed length feature vector. We use Glove vectors for word embedding and average of word embeddings to represent a document (here title and description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 85930 documents\n",
      "Number of words found: 260983\n",
      "Tokenized each item description (85930, 500)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "maxlen = 500\n",
    "embedding_dim = 50\n",
    "\n",
    "docs = []\n",
    "for item in all_vals:\n",
    "    doc_text = ''\n",
    "    if 'title' in item:\n",
    "        doc_text += item['title']\n",
    "    if 'description' in item:\n",
    "        doc_text += item['description']\n",
    "    if len(doc_text) == 0:\n",
    "        doc_text = 'not available'\n",
    "    docs.append(doc_text)\n",
    "print(f\"Total {len(docs)} documents\")\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size-1, lower=True, split=' ')  # 1 ... 4999\n",
    "# tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ', oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "print(f\"Number of words found: {len(tokenizer.word_index)}\")\n",
    "\n",
    "vocab = [k for k,v in tokenizer.word_index.items() if v < vocab_size]  # 1 ... 4999\n",
    "tensor = tokenizer.texts_to_sequences(docs)\n",
    "tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)\n",
    "print(f\"Tokenized each item description\", tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim, vocab_size):\n",
    "    # vocab_size = len(word_index) + 1\n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    all_words = set()\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            all_words.add(word)\n",
    "            if word in word_index:\n",
    "                idx = word_index.index(word) + 1\n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[\n",
    "                    :embedding_dim\n",
    "                ]\n",
    "    count_missing = len(set(word_index) - all_words)\n",
    "    if count_missing > 0:\n",
    "        print(f\"!!! {count_missing} words could not be mapped\")\n",
    "    return embedding_matrix, all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! 334 words could not be mapped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5000, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create word embedding matrix - dimension = |V| X word-embedding dimension\n",
    "embedding_matrix, glove_vocab = create_embedding_matrix(\n",
    "    os.path.join(glove_dir, glove_file), vocab, embedding_dim, vocab_size)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Item Embedding Matrix\n",
    "\n",
    "For each item we take all the word embeddings and take the average. We can also divide by sqrt(n) as was done by [?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85930/85930 [01:13<00:00, 1173.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text based item embedding matrix (85930, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_items, seq_len = tensor.shape\n",
    "# big_tensor = np.zeros((num_items + 1, seq_len))\n",
    "# big_tensor[1 : num_items + 1, :] = tensor\n",
    "# del tensor\n",
    "# num_items, seq_len\n",
    "\n",
    "item_embeddings = np.zeros((num_items, embedding_matrix.shape[1]))\n",
    "# item_embeddings = np.zeros((num_items + 1, embedding_matrix.shape[1]))\n",
    "\n",
    "for item in tqdm(range(num_items)):\n",
    "    word_indices = tensor[item, :]\n",
    "    word_indices = [int(i) for i in word_indices if i != 0]\n",
    "    if len(word_indices) > 0:\n",
    "        word_vectors = embedding_matrix[word_indices, :]\n",
    "        mean_vector = word_vectors.mean(axis=0)\n",
    "        item_embeddings[item, :] = mean_vector\n",
    "#     else:\n",
    "#         print(f\"Missing embedding for item-{item}\")\n",
    "\n",
    "print(f\"Text based item embedding matrix\", item_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write raw word embedding file - basic nodal features\n",
    "with open(text_embed_filename, 'wb') as handle:\n",
    "    pickle.dump(item_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Node File\n",
    "\n",
    "The file has all the node details, node-id, nodal features and class information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85930it [00:04, 18195.24it/s]\n"
     ]
    }
   ],
   "source": [
    "classes = []\n",
    "class_index = 1\n",
    "with open('ae_nodes.txt', 'w') as fw:\n",
    "    for ii, item in tqdm(enumerate(all_vals)):\n",
    "        out_txt = [item['id']] + list(item_embeddings[ii, :]) + [item['categories'][0][class_index]]\n",
    "        out_txt = [str(e) for e in out_txt]\n",
    "        fw.write('\\t'.join(out_txt) + '\\n')\n",
    "        classes.append(item['categories'][0][class_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'GPS & Navigation': 1566,\n",
       "         'Computers & Accessories': 37416,\n",
       "         'eBook Readers & Accessories': 892,\n",
       "         'Accessories & Supplies': 11932,\n",
       "         'Camera & Photo': 15404,\n",
       "         'Portable Audio & Video': 6996,\n",
       "         'Car & Vehicle Electronics': 3819,\n",
       "         'Home Audio': 2363,\n",
       "         'Television & Video': 4029,\n",
       "         'Security & Surveillance': 570,\n",
       "         'Interior Accessories': 2,\n",
       "         'Accessories': 457,\n",
       "         'Cases': 243,\n",
       "         'Electronics Warranties': 193,\n",
       "         'Service & Replacement Plans': 21,\n",
       "         'Tools & Equipment': 5,\n",
       "         'C': 1,\n",
       "         'Cell Phones': 10,\n",
       "         'Luggage & Travel Gear': 4,\n",
       "         'Hair Care': 1,\n",
       "         'Connected Devices': 4,\n",
       "         'Car Care': 2})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Edge File\n",
    "\n",
    "This file has three columns for each edge - starting node, ending node and edge type (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85930/85930 [00:03<00:00, 23230.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1679007 edges created\n"
     ]
    }
   ],
   "source": [
    "count_edge = 0\n",
    "criteria = ['bought_together', 'buy_after_viewing', 'also_bought'] # 'also_viewed', 'also_bought',\n",
    "add_edge_type = True\n",
    "with open('ae_edges.txt', 'w') as fw:\n",
    "    for e in tqdm(entity_dict):\n",
    "        if 'related' in entity_dict[e]:\n",
    "            for criterion in criteria:\n",
    "                if criterion in entity_dict[e]['related']:\n",
    "                    connected = entity_dict[e]['related'][criterion]\n",
    "                    for e2 in connected:\n",
    "                        if e2 in entity_dict:\n",
    "                            tuples = [entity_dict[e]['id'], entity_dict[e2]['id']]\n",
    "                            if add_edge_type:\n",
    "                                tuples.append(criterion)\n",
    "                            out_txt = '\\t'.join([str(e) for e in tuples])\n",
    "                            fw.write(out_txt + '\\n')\n",
    "                            count_edge += 1\n",
    "\n",
    "print(f\"Total {count_edge} edges created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Graph Convolution Network Model\n",
    "\n",
    "    - cluster-gcn-node-classification.ipynb for no edge type\n",
    "    - rgcn-node-classification.ipynb for edges with edge type\n",
    "    - load the node embeddings from a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85930, 64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('ae_item_embeddings.pkl', 'rb') as handle:\n",
    "    emb = pickle.load(handle)\n",
    "    \n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_udict = {v:k for k, v in udict.items()}\n",
    "inv_idict = {v:k for k, v in idict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A2O2D7JV0QU630'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_udict[3932]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B00GTGETFG', '1400198400'),\n",
       " ('B009A5204K', '1393977600'),\n",
       " ('B000LRMS66', '1173484800'),\n",
       " ('B001BRXW74', '1393977600'),\n",
       " ('B003FVJYF8', '1390867200'),\n",
       " ('B001KZ6C74', '1278115200'),\n",
       " ('B000EXS1BS', '1173484800'),\n",
       " ('B004W2JKWG', '1318204800'),\n",
       " ('B00BUCLVZU', '1402099200'),\n",
       " ('B00004ZCJE', '1244937600'),\n",
       " ('B0001P4V36', '1162166400'),\n",
       " ('B000EG46O6', '1173484800'),\n",
       " ('B00003CWG2', '1209081600'),\n",
       " ('B005FW56WA', '1317340800'),\n",
       " ('B000DZDSME', '1178064000'),\n",
       " ('B000SKVZOM', '1232323200'),\n",
       " ('B0002EXJ8Y', '1145750400'),\n",
       " ('B0007KQWDC', '1123459200'),\n",
       " ('B00685423M', '1337904000'),\n",
       " ('B001IYS1QM', '1261612800'),\n",
       " ('B005TI1ILS', '1401580800'),\n",
       " ('B00065L5TE', '1185667200'),\n",
       " ('B002E3AIG2', '1269734400'),\n",
       " ('B000GWLL0K', '1173484800'),\n",
       " ('B00F6EL6O4', '1393977600'),\n",
       " ('B00006J07K', '1185667200'),\n",
       " ('B008TZJ126', '1376784000'),\n",
       " ('B00008VSLB', '1209081600'),\n",
       " ('B0002EXJ98', '1197849600'),\n",
       " ('B000COZ43C', '1170720000'),\n",
       " ('B001MKKA5C', '1278115200'),\n",
       " ('B007C8DWFI', '1362700800'),\n",
       " ('B009FN72PO', '1362700800')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history['A2O2D7JV0QU630']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68787,\n",
       " 81707,\n",
       " 50744,\n",
       " 62280,\n",
       " 18720,\n",
       " 68250,\n",
       " 24776,\n",
       " 890,\n",
       " 38317,\n",
       " 63560,\n",
       " 48670,\n",
       " 42709,\n",
       " 83276,\n",
       " 33038,\n",
       " 47622,\n",
       " 30823,\n",
       " 62309,\n",
       " 67597,\n",
       " 50720,\n",
       " 14088,\n",
       " 69420,\n",
       " 18548,\n",
       " 69397,\n",
       " 4945,\n",
       " 38938,\n",
       " 79255,\n",
       " 50750,\n",
       " 61332,\n",
       " 18576,\n",
       " 19084,\n",
       " 83278,\n",
       " 43810,\n",
       " 26051]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idict[it[0]] for it in sorted(user_history['A2O2D7JV0QU630'], key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B003JTHMRS\n",
      "B0030EV78M\n",
      "B005LXNTT0\n",
      "B004P616IU\n",
      "B005UE894U\n",
      "B00CB3E50U\n",
      "B001AJJON4\n",
      "B003960EYO\n",
      "B0023SJCII\n"
     ]
    }
   ],
   "source": [
    "items = [61528, 3052, 12906, 62823, 19661, 70994, 69609, 58134, 47850]\n",
    "for it in reversed(items):\n",
    "    print(inv_idict[it])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31227,\n",
       " [('B000BUK7KW', '1248912000'),\n",
       "  ('B005LLS7WG', '1320451200'),\n",
       "  ('B005O0R9UA', '1341446400'),\n",
       "  ('B0038A9HSK', '1341964800'),\n",
       "  ('B008DR5R1O', '1342483200'),\n",
       "  ('B003VVH8Y6', '1344211200'),\n",
       "  ('B005DKZTMG', '1353888000'),\n",
       "  ('B0092HP3GS', '1365552000'),\n",
       "  ('B006U3O566', '1369958400'),\n",
       "  ('B00005T3FS', '1369958400'),\n",
       "  ('B0090J652Y', '1375488000'),\n",
       "  ('B002RL9XQM', '1376438400'),\n",
       "  ('B004GJURHM', '1381190400'),\n",
       "  ('B005B3VO24', '1382054400'),\n",
       "  ('B008U69DDG', '1389916800'),\n",
       "  ('B00BUCLVZU', '1389916800'),\n",
       "  ('B0042X8W0Q', '1389916800'),\n",
       "  ('B00DC8IEE6', '1389916800'),\n",
       "  ('B008C1JC4O', '1393200000'),\n",
       "  ('B00DBA9YD0', '1393200000'),\n",
       "  ('B008DWIFP4', '1404345600'),\n",
       "  ('B004HD4L2E', '1404691200')])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udict['A2STI6QRXQR2A9'], sorted(user_history['A2STI6QRXQR2A9'], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation Differences\n",
    "\n",
    "    - original data (33 interactions)\n",
    "            1       A2O2D7JV0QU630  B0007KQWDC      1123459200      Point & Shoot Digital Cameras\n",
    "            1       A2O2D7JV0QU630  B0002EXJ8Y      1145750400      Remote-Control Extenders\n",
    "            1       A2O2D7JV0QU630  B0001P4V36      1162166400      Camera\n",
    "            1       A2O2D7JV0QU630  B000COZ43C      1170720000      Camera Batteries\n",
    "            1       A2O2D7JV0QU630  B000LRMS66      1173484800      Vehicle Mounts\n",
    "            1       A2O2D7JV0QU630  B000EXS1BS      1173484800      Vehicle GPS\n",
    "            1       A2O2D7JV0QU630  B000EG46O6      1173484800      Digital Camera Lenses\n",
    "            1       A2O2D7JV0QU630  B000GWLL0K      1173484800      MP3 Player Accessories\n",
    "            1       A2O2D7JV0QU630  B000DZDSME      1178064000      Point & Shoot Digital Cameras\n",
    "            1       A2O2D7JV0QU630  B00065L5TE      1185667200      Camera\n",
    "            1       A2O2D7JV0QU630  B00006J07K      1185667200      Binocular, Camera & Camcorder Straps\n",
    "            1       A2O2D7JV0QU630  B0002EXJ98      1197849600      Component Receivers\n",
    "            1       A2O2D7JV0QU630  B00003CWG2      1209081600      Splitters\n",
    "            1       A2O2D7JV0QU630  B00008VSLB      1209081600      Splitters\n",
    "            1       A2O2D7JV0QU630  B000SKVZOM      1232323200      Shoe Mount Flashes\n",
    "            1       A2O2D7JV0QU630  B00004ZCJE      1244937600      Skylight & UV Filters\n",
    "            1       A2O2D7JV0QU630  B001IYS1QM      1261612800      USB Flash Drives\n",
    "            1       A2O2D7JV0QU630  B002E3AIG2      1269734400      Routers\n",
    "            1       A2O2D7JV0QU630  B001KZ6C74      1278115200      Camcorder\n",
    "            1       A2O2D7JV0QU630  B001MKKA5C      1278115200      Vehicle Mounts\n",
    "            1       A2O2D7JV0QU630  B005FW56WA      1317340800      Cases\n",
    "            1       A2O2D7JV0QU630  B004W2JKWG      1318204800      Internal Solid State Drives\n",
    "            1       A2O2D7JV0QU630  B00685423M      1337904000      Print Servers\n",
    "            1       A2O2D7JV0QU630  B007C8DWFI      1362700800      Vehicle Mounts\n",
    "            1       A2O2D7JV0QU630  B009FN72PO      1362700800      Splitters\n",
    "            1       A2O2D7JV0QU630  B008TZJ126      1376784000      Streaming Media Players\n",
    "            1       A2O2D7JV0QU630  B003FVJYF8      1390867200      F-Pin-Coaxial Tip\n",
    "            1       A2O2D7JV0QU630  B009A5204K      1393977600      Bluetooth Headsets\n",
    "            1       A2O2D7JV0QU630  B001BRXW74      1393977600      TV Antennas\n",
    "            1       A2O2D7JV0QU630  B00F6EL6O4      1393977600      USB Network Adapters\n",
    "            1       A2O2D7JV0QU630  B00GTGETFG      1400198400      Travel Chargers\n",
    "            1       A2O2D7JV0QU630  B005TI1ILS      1401580800      Component Receivers\n",
    "            1       A2O2D7JV0QU630  B00BUCLVZU      1402099200      Streaming Media Players\n",
    "    \n",
    "    - processed data (sub-sampled)\n",
    "    train   1       A2O2D7JV0QU630  B000LRMS66      1173484800      Vehicle Mounts\n",
    "    train   1       A2O2D7JV0QU630  B000EXS1BS      1173484800      Vehicle GPS\n",
    "    train   1       A2O2D7JV0QU630  B0002EXJ98      1197849600      Component Receivers\n",
    "    train   1       A2O2D7JV0QU630  B00004ZCJE      1244937600      Skylight & UV Filters\n",
    "    train   1       A2O2D7JV0QU630  B001IYS1QM      1261612800      USB Flash Drives\n",
    "    train   1       A2O2D7JV0QU630  B004W2JKWG      1318204800      Internal Solid State Drives\n",
    "    train   1       A2O2D7JV0QU630  B003FVJYF8      1390867200      F-Pin-Coaxial Tip\n",
    "    train   1       A2O2D7JV0QU630  B009A5204K      1393977600      Bluetooth Headsets\n",
    "    train   1       A2O2D7JV0QU630  B001BRXW74      1393977600      TV Antennas\n",
    "    train   1       A2O2D7JV0QU630  B00GTGETFG      1400198400      Travel Chargers\n",
    "    valid   1       A2O2D7JV0QU630  B005TI1ILS      1401580800      Component Receivers\n",
    "    test    1       A2O2D7JV0QU630  B00BUCLVZU      1402099200      Streaming Media Players\n",
    "\n",
    "    - sli-rec type:\n",
    "        - train_data\n",
    "            1       A2O2D7JV0QU630  B000EXS1BS      Vehicle GPS     1173484800      B000LRMS66      Vehicle Mounts  1173484800\n",
    "            1       A2O2D7JV0QU630  B0002EXJ98      Component Receivers     1197849600      B000LRMS66,B000EXS1BS   Vehicle Mounts,Vehicle GPS      1173484800,1173484800\n",
    "            1       A2O2D7JV0QU630  B00004ZCJE      Skylight & UV Filters   1244937600      B000LRMS66,B000EXS1BS,B0002EXJ98        Vehicle Mounts,Vehicle GPS,Component Receivers  1173484800,1173484800,1197849600\n",
    "            1       A2O2D7JV0QU630  B001IYS1QM      USB Flash Drives        1261612800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE     Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters    1173484800,1173484800,1197849600,1244937600\n",
    "            1       A2O2D7JV0QU630  B004W2JKWG      Internal Solid State Drives     1318204800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM  Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives   1173484800,1173484800,1197849600,1244937600,1261612800\n",
    "            1       A2O2D7JV0QU630  B003FVJYF8      F-Pin-Coaxial Tip       1390867200      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG       Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives       1173484800,1173484800,1197849600,1244937600,1261612800,1318204800\n",
    "            1       A2O2D7JV0QU630  B009A5204K      Bluetooth Headsets      1393977600      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8    Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip     1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200\n",
    "            1       A2O2D7JV0QU630  B001BRXW74      TV Antennas     1393977600      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets  1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600\n",
    "            1       A2O2D7JV0QU630  B00GTGETFG      Travel Chargers 1400198400      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74      Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600\n",
    "\n",
    "    valid_data\n",
    "            1       A2O2D7JV0QU630  B005TI1ILS      Component Receivers     1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B001L1H0SC      Micro SD Cards  1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B000T95Q1U      Adapter Rings   1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B00BE68UZ6      Cases   1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B009WZRAQQ      Cases   1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B0018Z2Q2G      Headphones      1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B007KFLV9W      Weather Radios  1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B0001D3K8A      Routers 1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B002UT42UI      SD & SDHC Cards 1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "            0       A2O2D7JV0QU630  B003FVVMS0      Subwoofer Cables        1401580800      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG   Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers      1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400\n",
    "\n",
    "        - test data\n",
    "            1       A2O2D7JV0QU630  B00BUCLVZU      Streaming Media Players 1402099200      B000LRMS66,B000EXS1BS,B0002EXJ98,B00004ZCJE,B001IYS1QM,B004W2JKWG,B003FVJYF8,B009A5204K,B001BRXW74,B00GTGETFG,B005TI1ILS        Vehicle Mounts,Vehicle GPS,Component Receivers,Skylight & UV Filters,USB Flash Drives,Internal Solid State Drives,F-Pin-Coaxial Tip,Bluetooth Headsets,TV Antennas,Travel Chargers,Component Receivers  1173484800,1173484800,1197849600,1244937600,1261612800,1318204800,1390867200,1393977600,1393977600,1400198400,1401580800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SASRec Feature Creation\n",
    "\n",
    "sorted user history: [68787, 81707, 50744, 62280, 18720, 68250, 24776, 890, 38317, 63560, 48670,\n",
    " 42709, 83276, 33038, 47622, 30823, 62309, 67597, 50720, 14088, 69420, 18548, 69397, 4945, 38938,\n",
    " 79255, 50750, 61332, 18576, 19084, 83278,\n",
    " `43810`,\n",
    " `26051`] where the last two are kept for validation and test, espectively.\n",
    "\n",
    "user-id: 3932\n",
    "\n",
    "*seq*: [0 ... 0, 68787 81707 50744 62280 18720 68250 24776   890 38317 63560\n",
    " 48670 42709 83276 33038 47622 30823 62309 67597 50720 14088 69420 18548\n",
    " 69397  4945 38938 79255 50750 61332 18576 19084]\n",
    " \n",
    "*pos*: [0 ... 0, 81707 50744 62280 18720 68250 24776   890 38317 63560 48670\n",
    " 42709 83276 33038 47622 30823 62309 67597 50720 14088 69420 18548 69397\n",
    "  4945 38938 79255 50750 61332 18576 19084 83278]\n",
    "  \n",
    "*neg*: [0 ... 0, 35405 14579 57151 76896 66003 47718 36914 64425 12544 33579\n",
    " 36497 39168 37315 77772 11931 30812 18501  2028 29749 68490 79277  4844\n",
    " 78272 76118 31696 85199 51452 55959  3604 15751]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cat in category_dict:\n",
    "#     ratio = len(category_dict[cat])/count\n",
    "#     if ratio > 0.1:\n",
    "#         print(cat, len(category_dict[cat]), ratio)\n",
    "        \n",
    "# for cat in category_dict:\n",
    "#     if 10 < len(category_dict[cat]) < 100:\n",
    "#         print(cat, len(category_dict[cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_all_files(out_dir, categories, entities, max_examples=None):\n",
    "    include_categories = []\n",
    "    for cat in categories:\n",
    "        ratio = len(categories[cat])/count\n",
    "#         if ratio > cutoff and ratio < 0.8:\n",
    "        if 10 < len(category_dict[cat]) < 100:\n",
    "            include_categories.append(cat)\n",
    "    \n",
    "    relations = copy.deepcopy(include_categories)\n",
    "    include_categories.extend(['also_viewed', 'buy_after_viewing'])\n",
    "    print(f\"Added {len(include_categories)} relations\")\n",
    "        \n",
    "    # entity2id.txt\n",
    "    with open(os.path.join(out_dir, 'AE', 'entity2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(entities)) + '\\n')\n",
    "        for e in entities:\n",
    "            fw.write(e + '\\t' + str(entities[e]['id']) + '\\n')\n",
    "    \n",
    "    # relation2id.txt\n",
    "    with open(os.path.join(out_dir, 'AE', 'relation2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(include_categories)) + '\\n')\n",
    "        for ii, r in enumerate(include_categories):\n",
    "            fw.write(r + '\\t' + str(ii) + '\\n')\n",
    "    \n",
    "    # train2id.txt\n",
    "    train, valid, test = [], [], []\n",
    "    count_train, count_valid, count_test = 0, 0, 0\n",
    "\n",
    "    for jj, cat in enumerate(relations):\n",
    "        similar_entities = categories[cat]\n",
    "        print(cat, len(similar_entities))\n",
    "        for e1 in similar_entities:\n",
    "            for e2 in similar_entities:\n",
    "                if e1 != e2:\n",
    "                    tuples = (entities[e1]['id'], entities[e2]['id'], jj)\n",
    "                    rnd = random.random()\n",
    "                    if rnd <= 0.7:\n",
    "                        train.append(tuples)\n",
    "                        count_train += 1\n",
    "                    elif rnd <= 0.85:\n",
    "                        valid.append(tuples)\n",
    "                        count_valid += 1\n",
    "                    else:\n",
    "                        test.append(tuples)\n",
    "                        count_test += 1\n",
    "    \n",
    "    print(f\"Train: {count_train}, Validation: {count_valid} and Test: {count_test}\")\n",
    "    \n",
    "    for e in entities:\n",
    "        if 'related' in entities[e]:\n",
    "            if 'also_viewed' in entities[e]['related']:\n",
    "                connected = entities[e]['related']['also_viewed']\n",
    "                jj = include_categories.index('also_viewed')\n",
    "                for e2 in connected:\n",
    "                    if e2 in entities:\n",
    "                        tuples = (entities[e]['id'], entities[e2]['id'], jj)\n",
    "                        rnd = random.random()\n",
    "                        if rnd <= 0.7:\n",
    "                            train.append(tuples)\n",
    "                            count_train += 1\n",
    "                        elif rnd <= 0.85:\n",
    "                            valid.append(tuples)\n",
    "                            count_valid += 1\n",
    "                        else:\n",
    "                            test.append(tuples)\n",
    "                            count_test += 1\n",
    "                            \n",
    "            if 'buy_after_viewing' in entities[e]['related']:\n",
    "                connected = entities[e]['related']['buy_after_viewing']\n",
    "                jj = include_categories.index('buy_after_viewing')\n",
    "                for e2 in connected:\n",
    "                    if e2 in entities:\n",
    "                        tuples = (entities[e]['id'], entities[e2]['id'], jj)\n",
    "                        rnd = random.random()\n",
    "                        if rnd <= 0.7:\n",
    "                            train.append(tuples)\n",
    "                            count_train += 1\n",
    "                        elif rnd <= 0.85:\n",
    "                            valid.append(tuples)\n",
    "                            count_valid += 1\n",
    "                        else:\n",
    "                            test.append(tuples)\n",
    "                            count_test += 1\n",
    "    \n",
    "    print(f\"Train: {count_train}, Validation: {count_valid} and Test: {count_test}\")\n",
    "    \n",
    "    random.shuffle(train)\n",
    "    random.shuffle(valid)\n",
    "    random.shuffle(test)\n",
    "    \n",
    "    if max_examples:\n",
    "        train = train[:max_examples]\n",
    "        valid = valid[:max_examples]\n",
    "        test = test[:max_examples]\n",
    "    \n",
    "    with open(os.path.join(out_dir, 'AE', 'train2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(train)) + '\\n')\n",
    "        for tup in train:\n",
    "            out = [str(e) for e in tup]\n",
    "            fw.write(' '.join(out) + '\\n')\n",
    "        \n",
    "    with open(os.path.join(out_dir, 'AE', 'valid2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(valid)) + '\\n')\n",
    "        for tup in valid:\n",
    "            out = [str(e) for e in tup]\n",
    "            fw.write(' '.join(out) + '\\n')\n",
    "        \n",
    "    with open(os.path.join(out_dir, 'AE', 'test2id.txt'), 'w') as fw:\n",
    "        fw.write(str(len(test)) + '\\n')\n",
    "        for tup in test:\n",
    "            out = [str(e) for e in tup]\n",
    "            fw.write(' '.join(out) + '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 219 relations\n",
      "Stylus Pens 63\n",
      "USB Fans 91\n",
      "VHS 72\n",
      "Hi-8 45\n",
      "Color Correction & Compensation Filters 94\n",
      "APS Cameras 59\n",
      "VHS-C 23\n",
      "Systems 24\n",
      "Wireless Jack Systems 25\n",
      "VCR Rewinders 32\n",
      "Caller ID Displays 89\n",
      "Cable Straps 64\n",
      "PS/2 Cables 50\n",
      "SCSI Cables 57\n",
      "Zip Discs 45\n",
      "Minidisc Players 51\n",
      "External Zip Drives 52\n",
      "Internal Modems 84\n",
      "Tape Decks 57\n",
      "Minidiscs 32\n",
      "Security Locks 72\n",
      "Automotive 44\n",
      "CD Recorders 55\n",
      "Tuners 95\n",
      "CD-RW Discs 77\n",
      "SmartMedia Cards 36\n",
      "Radar Systems 14\n",
      "Changers 46\n",
      "Handheld CB Radios 11\n",
      "Catadioptric 84\n",
      "Barlow Lenses 29\n",
      "Telescope Cases 36\n",
      "Photo Adapters 27\n",
      "Tape Libraries 19\n",
      "Multimedia Cards 48\n",
      "Parallel Port Cards 59\n",
      "DVD-RAM Discs 53\n",
      "Bluetooth Headsets 99\n",
      "Holsters & Clips 24\n",
      "VTR Decks 17\n",
      "Cassette Storage 21\n",
      "Projectors 36\n",
      "Slide Projectors 35\n",
      "Single-Use Cameras 99\n",
      "Presentation Supplies 32\n",
      "Binding Machine Supplies 13\n",
      "Calculator Accessories 93\n",
      "Tabletop & Travel Tripods 22\n",
      "TV Turntables 44\n",
      "Port Tubes 22\n",
      "Dew Caps 37\n",
      "Fixed-mount CB Radios 74\n",
      "Binocular Accessories 56\n",
      "Clock Radios 61\n",
      "Mounting Accessories 87\n",
      "Satellite Finders 55\n",
      "DLT Cleaning Cartridges 39\n",
      "Overhead Supplies 18\n",
      "Graduated Color Filters 65\n",
      "Brushes 45\n",
      "Step-Up Rings 96\n",
      "Distribution Panels 92\n",
      "Line Conditioners 72\n",
      "Parallel Adapters 25\n",
      "Film Processing Equipment 55\n",
      "Projector Bags & Cases 45\n",
      "Projector Cases 33\n",
      "Speaker Accessories 47\n",
      "Stereo Microscopes 58\n",
      "Phone Cards 30\n",
      "Satellite Dishes 40\n",
      "Rangefinder Cameras 19\n",
      "RF Modulators 79\n",
      "DVD+RW Discs 71\n",
      "Barn Doors 30\n",
      "External TV Tuners 77\n",
      "Hi-Fi & HT Cabinets 90\n",
      "Firewire Adapters 18\n",
      "Crossover Parts 73\n",
      "Cables 24\n",
      "Grills 90\n",
      "Finder Scopes 35\n",
      "DATs 18\n",
      "USB-to-VGA Adapters 98\n",
      "Cable Raceways 50\n",
      "Computer Vacuums 69\n",
      "Device Servers 22\n",
      "MiniSD Cards 69\n",
      "Warranties & Services 71\n",
      "Computer Equipment Warranties 67\n",
      "USB Lamps 88\n",
      "Video Multiplexers & Quads 21\n",
      "Biometrics 75\n",
      "Cell Phones 20\n",
      "TV Tuners 38\n",
      "Compressed Air 16\n",
      "Surface-mounted Speakers 19\n",
      "Tweeter Diaphragms 48\n",
      "Slide, Negative & Print Pages 72\n",
      "Photo Enlarging Paper 68\n",
      "Monopod Heads 65\n",
      "Chemicals 60\n",
      "Diopters 54\n",
      "Filter Cases 22\n",
      "Light Boxes & Loupes 52\n",
      "Loupes 51\n",
      "Archival Storage Binders 16\n",
      "Safelights 41\n",
      "Binocular Cases 12\n",
      "Tripod & Monopod Cases 48\n",
      "Flash Tubes 23\n",
      "Grey Cards 36\n",
      "Slaves 55\n",
      "Medium & Large-Format Cameras 36\n",
      "Diagonals 13\n",
      "Copying Equipment 18\n",
      "Guiders & Wedges 14\n",
      "Printers & Scanners 52\n",
      "Portable Photo Printers 52\n",
      "Center Columns 17\n",
      "Marine Antennas 91\n",
      "Opera Glasses 55\n",
      "External Sound Cards 48\n",
      "Tools & Equipment 31\n",
      "Mounting Kits 78\n",
      "Liquid Cleaners 15\n",
      "Voice Dialers 33\n",
      "Horns & Sirens 87\n",
      "Step-Down Rings 24\n",
      "Subwoofer Amplifiers 41\n",
      "Aircraft Accessories 67\n",
      "Marine Speakers 11\n",
      "Cable Sleeves 98\n",
      "Enclosed Subwoofer Systems 30\n",
      "Speaker Grills 94\n",
      "Signal Boosters 36\n",
      "Feet & Spikes 36\n",
      "Dust Caps 66\n",
      "Handles 29\n",
      "Case Hardware & Latches 15\n",
      "Home Audio Crossovers & Parts 27\n",
      "Video Transmission Systems 68\n",
      "Connecting Blocks 31\n",
      "Power Packs 15\n",
      "Carpet & Vinyl 28\n",
      "Handheld Digital Photo Viewers 40\n",
      "Service & Replacement Plans 90\n",
      "Service Plans 80\n",
      "Line Cords 32\n",
      "Barking-Dog Alarms 11\n",
      "GPS Trackers 49\n",
      "Headsets & Intercoms 85\n",
      "Surveillance Camera Lenses 71\n",
      "Cycling GPS Units 56\n",
      "Charging Stations 30\n",
      "Component Speakers 15\n",
      "Internal Batteries 95\n",
      "Data Cables 79\n",
      "Motorcycle GPS 29\n",
      "Traffic Message Channel (TMC) Receiver Modules 29\n",
      "Shooting Tables 35\n",
      "Specialty Film Cameras 19\n",
      "Replacement Parts 11\n",
      "Aviation GPS 38\n",
      "Travel Chargers 51\n",
      "Professional Video Cameras 60\n",
      "Car Accessories 60\n",
      "BD-RE Discs 72\n",
      "Floor Cord Covers 80\n",
      "Mini-SAS Cables 26\n",
      "Hard Drive Cases 15\n",
      "Continuous Output Lighting 65\n",
      "HDD Cooling Fans 19\n",
      "Autopilots 22\n",
      "Tripod Mount Rings 46\n",
      "Video Studio 51\n",
      "External Battery Packs 84\n",
      "Video Monitors 37\n",
      "Follow-Focus Levers 52\n",
      "Camera & Camcorder Lens Bundles 86\n",
      "Solar Chargers 45\n",
      "Car Cradles & Mounts 45\n",
      "Car Mounts 40\n",
      "SCSI Adapters 22\n",
      "Graphics Card Fans 26\n",
      "Car Care 24\n",
      "Cloths & Towels 24\n",
      "Chamois 24\n",
      "Matte Boxes 22\n",
      "Aircraft Avionics 17\n",
      "Bluetooth Speakers 86\n",
      "Sandbags 31\n",
      "Motorcycle Accessory Mounts 26\n",
      "Camera Cine Dollies 12\n",
      "Camera Cranes 28\n",
      "IR Illuminators 11\n",
      "Lens Supports 38\n",
      "Laptop Barebones 21\n",
      "External Solid State Drives 61\n",
      "Motorcycle Bluetooth Headsets 43\n",
      "Aviation Handheld Radios 19\n",
      "Color Calibration Charts 20\n",
      "Cell Phone Docks 12\n",
      "Vehicle Tracking and Monitoring Modules 71\n",
      "Installation Services 76\n",
      "Kick-Panel Enclosures 27\n",
      "Compact System Camera Lenses 59\n",
      "Satellite Dish Mounts 17\n",
      "Connected Devices 12\n",
      "Lightning Cables 80\n",
      "Digital Handwriting Pads 13\n",
      "Thunderbolt Cables 20\n",
      "In-Mirror Video 21\n",
      "Compact System Camera Bundles 22\n",
      "Speaker Repair Accessories 18\n",
      "USB Beverage Warmers 18\n",
      "Microscope Accessories 26\n",
      "Train: 407065, Validation: 87246 and Test: 86995\n",
      "Train: 3251152, Validation: 697295 and Test: 696633\n"
     ]
    }
   ],
   "source": [
    "write_all_files(out_dir='/recsys_data/RecSys/OpenKE/benchmarks/',\n",
    "                categories=category_dict,\n",
    "                entities=entity_dict,\n",
    "                max_examples=10000\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0545016266' in entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 498195,\n",
       " 'related': {'also_viewed': ['B0007T27H8', 'B00425S1H8', 'B000BI95W0'],\n",
       "  'buy_after_viewing': ['B0007T27H8', 'B00425S1H8']}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict['BT008T2BGK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38726\n"
     ]
    }
   ],
   "source": [
    "desc_dict = dict()\n",
    "count_missing = 0\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if 'description' not in jdict:\n",
    "            count_missing += 1\n",
    "        else:\n",
    "            desc_dict[jdict['asin']] = jdict['description']\n",
    "print(count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n"
     ]
    }
   ],
   "source": [
    "img_dict = dict()\n",
    "count_missing = 0\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if 'imUrl' not in jdict:\n",
    "            count_missing += 1\n",
    "        else:\n",
    "            img_dict[jdict['asin']] = jdict['imUrl']\n",
    "print(count_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size: 2.87(W) x 8.(L) x 1.12(D)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "ss = 'Size: 2.875\"(W) x 8.5\"(L) x 1.125\"(D)'\n",
    "# ss.replace(r\"[0-9]\\\"\", '')\n",
    "re.sub(r\"[0-9]\\\"\", \"\", ss)\n",
    "\n",
    "#\n",
    "ss = '\"key\": \"HDTV\" accented by a subtle \"nook\" logo'\n",
    "re.sub(r\"[^:]\\s\\\"\\w|\\w\\\" \", \" \", ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63114, 85930)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B0013J5XZE'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 95536,\n",
       " 'related': {'also_bought': ['B000XB9GV0',\n",
       "   'B003HFB9B4',\n",
       "   'B003U8YAWI',\n",
       "   'B0028ZCXQ4',\n",
       "   'B000XB9GUG',\n",
       "   'B00494P6AW',\n",
       "   'B006LZQ6O2',\n",
       "   'B000XB4412',\n",
       "   'B001ENW61I',\n",
       "   'B00009UTL1',\n",
       "   '032171105X',\n",
       "   'B004BFZHO4',\n",
       "   'B003HF3A34',\n",
       "   'B003UOIMAS',\n",
       "   'B00452V288',\n",
       "   'B001M4HXB2',\n",
       "   'B0009BX0AM',\n",
       "   'B0028ZETAC',\n",
       "   'B0083Z6R4W',\n",
       "   'B00009UTZA',\n",
       "   'B001OKBLEE',\n",
       "   'B004BFXBXI',\n",
       "   'B001HAER88',\n",
       "   'B00DNADZME',\n",
       "   'B007FH1KX2',\n",
       "   'B000CLNHXY',\n",
       "   'B003OU51LG',\n",
       "   'B003GR6IUK',\n",
       "   'B0090BSSZO',\n",
       "   'B0007DDK7A',\n",
       "   'B00BXA7N6A',\n",
       "   'B002XUN2AA',\n",
       "   'B003N8SKDU',\n",
       "   'B007FH1LJU',\n",
       "   'B002YWHSVG',\n",
       "   'B003VBO4U2',\n",
       "   'B004YG7JXW',\n",
       "   'B003TYDBYQ',\n",
       "   'B001DIG46M',\n",
       "   'B003CRZFT4',\n",
       "   'B006ISEJ9Q',\n",
       "   '0321832752',\n",
       "   'B00HO0BYQS',\n",
       "   'B001E4LC6C',\n",
       "   '0321580141',\n",
       "   'B005GMWEI8',\n",
       "   'B001M4HTAW',\n",
       "   'B002Z3H36O',\n",
       "   'B004CBTCFC',\n",
       "   'B004YG7JV4',\n",
       "   'B00AA478UQ',\n",
       "   'B0034WR19Y',\n",
       "   'B00009UTL9',\n",
       "   'B0079M711S',\n",
       "   'B001TANZ0W',\n",
       "   'B00270VQTK',\n",
       "   'B00BWV72O8',\n",
       "   'B00009UTZJ',\n",
       "   'B003YFITC4',\n",
       "   'B000QDRRIE',\n",
       "   'B00BQ5UO1S',\n",
       "   'B001KELVS0',\n",
       "   'B004UG41XW',\n",
       "   'B003WGNSTE',\n",
       "   'B001CCAISE',\n",
       "   'B003UOIMBW',\n",
       "   'B004TGZ7WM',\n",
       "   'B005IQRMN4',\n",
       "   'B003AM38DG',\n",
       "   'B003Y30334',\n",
       "   'B004G3NW5M',\n",
       "   'B0034WR71G',\n",
       "   'B005RDU60O',\n",
       "   '0321803531',\n",
       "   'B003Y2EOBW',\n",
       "   'B001AHALEC',\n",
       "   'B0018LQVIA',\n",
       "   'B005KEL4BU',\n",
       "   'B00JQ4HZPO',\n",
       "   'B009RPBEEK',\n",
       "   '0321929500',\n",
       "   'B0082IX6MG',\n",
       "   'B0023RRPE2',\n",
       "   'B00F36K5Q0',\n",
       "   'B002SWIOOM',\n",
       "   'B00DCY29G4',\n",
       "   'B005UNPM3M',\n",
       "   'B002ZIMEMW',\n",
       "   'B001M4HTH0',\n",
       "   'B007ODZYRK',\n",
       "   '0240812255',\n",
       "   'B0000A4F05',\n",
       "   'B00551636O',\n",
       "   'B0053NWH14',\n",
       "   'B00GUQJZCW',\n",
       "   '111811289X',\n",
       "   '1608955702',\n",
       "   'B0040IWVBY',\n",
       "   'B0016XIQ1U'],\n",
       "  'bought_together': ['B000XB9GV0', 'B003HFB9B4'],\n",
       "  'buy_after_viewing': ['B000XB9GV0',\n",
       "   'B006LZQ6O2',\n",
       "   'B005KEL4NI',\n",
       "   'B00CYVNX0W']}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_dict['B0013J5XZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asin',\n",
       " 'brand',\n",
       " 'categories',\n",
       " 'description',\n",
       " 'imUrl',\n",
       " 'price',\n",
       " 'related',\n",
       " 'salesRank',\n",
       " 'title'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Items with Title & Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85930\n"
     ]
    }
   ],
   "source": [
    "ddict = {}\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if jdict['asin'] in idict:\n",
    "            ddict[jdict['asin']] = {}\n",
    "            if 'title' in jdict.keys():\n",
    "                ddict[jdict['asin']]['title'] = jdict['title']\n",
    "            if 'description' in jdict.keys():\n",
    "                ddict[jdict['asin']]['description'] = jdict['description']\n",
    "\n",
    "print(len(ddict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Honl Photo Professional Color Correction Gel Filter Kit for Photo Speed System',\n",
       " 'description': 'Use Honl Color Correction filters to color correct your strobes for tungsten, fluorescent or cool daylight lighting environments. Use CTO filters to match your flash output to tungsten lights, or simply to give a pleasing warm tone to your portraits. Use Full + Green to match your flash output to fluorescent lights. These superior filters are pre-cut with velcro strips attached so they can be quickly fastened to a Speed Strap (sold separately). Honl Filters can be used in conjunction with Honl Snoots, Gobos and Grids. The usable filter area is 2.5\" x 4\" and can be trimmed to fit individual strobes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddict['B0013J5XZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for item in ddict:\n",
    "    if len(ddict[item]) == 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nwords(txt, n):\n",
    "    return ' '.join(txt.split()[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18060\n"
     ]
    }
   ],
   "source": [
    "keep_words = 100\n",
    "max_len = 0\n",
    "with open('/recsys_data/RecSys/SASRec-tf2/data/ae_item_description.txt', 'w') as fw:\n",
    "    for item_number in range(1, 85931):\n",
    "        item_name = inv_idict[item_number]\n",
    "        temp_dict = ddict[item_name]\n",
    "        title, desc = '', ''\n",
    "        if 'title' in temp_dict:\n",
    "            title = temp_dict['title'].replace('\\n', '')\n",
    "        if 'description' in temp_dict:\n",
    "            desc = temp_dict['description'].replace('\\n', '')\n",
    "        otxt = title + ' ' + desc\n",
    "        if len(otxt.split()) > max_len:\n",
    "            max_len = len(otxt.split())\n",
    "        otxt = nwords(otxt, keep_words)\n",
    "        fw.write(otxt + '\\n')\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Items with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85930\n"
     ]
    }
   ],
   "source": [
    "imgdict = {}\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    for line in fr.readlines():\n",
    "        jdict = eval(line)\n",
    "        if jdict['asin'] in idict:\n",
    "            imgdict[jdict['asin']] = {}\n",
    "            if 'imUrl' in jdict.keys():\n",
    "                imgdict[jdict['asin']]['imUrl'] = jdict['imUrl']\n",
    "\n",
    "print(len(imgdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# Items with no image information\n",
    "count = 0\n",
    "for item in imgdict:\n",
    "    if len(imgdict[item]) == 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imUrl': 'http://ecx.images-amazon.com/images/I/2135RN5gz3L.jpg'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgdict['B0013J5XZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "import urllib\n",
    "\n",
    "item_name = 'B0013J5XZE'\n",
    "imgUrl = imgdict[item_name]['imUrl']\n",
    "imgData = urllib.request.urlopen(imgUrl).read()\n",
    "fileName = item_name + '_' + imgUrl.split('/')[-1]\n",
    "print(filename)\n",
    "output = open(fileName,'wb')\n",
    "output.write(imgData)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
