{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5353cd",
   "metadata": {},
   "source": [
    "## Build Input for Transformer Based Recommender with Adjacency Data\n",
    "\n",
    "SASRec [1] takes sequence of items (interacted by a user) as input and predicts the same sequence (shifted). The idea is to enrich this item sequence with additional information coming from the associated users. Thus, each item will have a sequence \n",
    "of users (sorted by time) as additional attributes. \n",
    "\n",
    "How to take care of the time aspect? While creating this graph only the users interacted before this time should be taken into account. Thus, the new dataset will look like \n",
    "        \n",
    "        user-id, item-id, all the users who interacted this item recently    \n",
    "        \n",
    "        11 56076 0\n",
    "        11 14037 15,10,12,13\n",
    "        11 4467 0\n",
    "        11 33810 268,41162,60222,56206,49801,10441,13000,14299\n",
    "        11 31260 12817,14614,30088,11039,25632,13,62373,47260,45849\n",
    "        11 28006 32489\n",
    "        11 16413 11359,11315,14025,34607,41079,11448,41139,40790,2541,10873,41072,41089,41083,13000,41099,29498,26935,9951,41060\n",
    "        11 55039 59475,11315,14025,34607,11448,61040,41089,41099,41083,2541,13407,20417,9951\n",
    "        11 20799 56213,56198\n",
    "        11 58690 3616\n",
    "        11 26147 0\n",
    "        11 66039 51660,52634,58450,51306,59567,10873\n",
    "        11 78708 58957\n",
    "        11 18158 3597,951,61249,2901,40226,60070,32243,32556,3635"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba7fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5e718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_original.txt\"\n",
    "output_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_graph.txt\"\n",
    "dict_filename = \"/recsys_data/RecSys/SASRec-tf2/data/ae_graph_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0197567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_with_time(fname, pname, sep=\"\\t\", file_write=False, max_seq_len=50, max_item_len=50):\n",
    "    User = defaultdict(list)\n",
    "    Items = set()\n",
    "    user_dict, item_dict = {}, {}\n",
    "    item_user = defaultdict(list)  # track user interaction time\n",
    "    final_item_user = dict()\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        for line in fr:\n",
    "            u, i, t = line.rstrip().split(sep)\n",
    "            t = float(t)\n",
    "            User[u].append((i, t))\n",
    "            Items.add(i)\n",
    "            item_user[i].append((u, t))\n",
    "            \n",
    "    print(len(User), len(Items))\n",
    "    \n",
    "    item_count = 1  # always start with 1\n",
    "    for item in Items:\n",
    "        item_dict[item] = item_count\n",
    "        item_count += 1\n",
    "\n",
    "    count_del = 0\n",
    "    user_count = 1  # start with 1\n",
    "\n",
    "    # get the user-ids\n",
    "    for user in User.keys():\n",
    "        if len(User[user]) <= 2:\n",
    "            count_del += 1\n",
    "        else:\n",
    "            User[user] = sorted(User[user], key=lambda x: x[1])\n",
    "            user_dict[user] = user_count\n",
    "            user_count += 1\n",
    "\n",
    "    if file_write:\n",
    "        print(f\"Writing data in {pname}\")\n",
    "        with open(pname, 'w') as fw:\n",
    "            for user in tqdm(User.keys()):\n",
    "                if len(User[user]) > 2:\n",
    "                    items = sorted(User[user], key=lambda x: x[1])\n",
    "                    current_items = [x[0] for x in items]\n",
    "                    user_id = user_dict[user]\n",
    "                    missing_user = 0\n",
    "                    for it in items:\n",
    "                        item_name, item_time = it\n",
    "                        ut = item_user[item_name]\n",
    "                        item_id = item_dict[item_name]\n",
    "                        prev_ut = [x for x in ut if x[1] < item_time]  # previous user-time\n",
    "                        prev_ut = sorted(prev_ut, key=lambda x: item_time - x[1])\n",
    "                        prev_u = [user] + [x[0] for x in prev_ut if x[0] in user_dict]\n",
    "                        \n",
    "                        # items interacted by these users (but before the current item_time)\n",
    "                        # and not in the current user's item list\n",
    "                        prev_it = [User[u] for u in prev_u]\n",
    "                        prev_it = [item for sublist in prev_it for item in sublist]\n",
    "                        prev_it = [x for x in prev_it if x[1] < item_time]\n",
    "                        prev_it = sorted(prev_it, key=lambda x: item_time - x[1])\n",
    "                        prev_i = [x[0] for x in prev_it if x[0] in item_dict]\n",
    "                        prev_i = [item for item in prev_i if item not in current_items]\n",
    "                        if len(prev_i) > 0:\n",
    "                            prev_i = [item_dict[item] for item in prev_i][:max_item_len]\n",
    "                            prev_i = [str(item) for item in prev_i]\n",
    "                        else:\n",
    "                            prev_i = ['0']\n",
    "                        \n",
    "                        prev_u = [str(user_id)] + [str(user_dict[x[0]]) for x in prev_ut if x[0] in user_dict][:max_seq_len]\n",
    "                        hist_u = ','.join(prev_u)\n",
    "                        hist_i = ','.join(prev_i)\n",
    "                        fw.write(sep.join([str(user_id), str(item_id), hist_u, hist_i]) + '\\n')\n",
    "        \n",
    "    print(user_count-1, count_del)\n",
    "    return user_dict, item_dict, User, item_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c8efc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63161 85930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/63161 [00:00<34:21, 30.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data in /recsys_data/RecSys/SASRec-tf2/data/ae_graph.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63161/63161 [29:03<00:00, 36.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63114 47\n",
      "Retained 63114 users with 85930 items from 63161 users\n"
     ]
    }
   ],
   "source": [
    "write_file = True\n",
    "max_user_list = 49\n",
    "max_item_list = 50\n",
    "udict, idict, user_history, item_history = data_process_with_time(interaction_filename, \n",
    "                                                                  output_filename, \n",
    "                                                                  \"\\t\", \n",
    "                                                                  write_file,\n",
    "                                                                  max_user_list,\n",
    "                                                                  max_item_list\n",
    "                                                                 )\n",
    "\n",
    "if write_file:\n",
    "    with open(dict_filename, 'wb') as handle:\n",
    "        pickle.dump((udict, idict, user_history), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Retained {len(udict)} users with {len(idict)} items from {len(user_history)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2db11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A2C8I2RQ0WG940', 1383523200.0), ('AM8OIQGVZEEKT', 1405468800.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'B005UEB5TQ', 'B000W3LJ6Y', 'B0089MVZDW', 'B00005TQ09', 'B0001Y7UAI', 'B00020BJA8', 'B000BQ7GW8', 'B000EPR7XO', 'B000M2GYF6', 'B001EH8FZA', 'B001EZRYYU'\n",
    "item_history['B005UEB5TQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef6346c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B003AVMRPM', 1276992000.0),\n",
       " ('B004AM5RB6', 1295568000.0),\n",
       " ('B003S68Q0Y', 1305504000.0),\n",
       " ('B007CS9WYI', 1339632000.0),\n",
       " ('B00BOZ1Y46', 1369440000.0),\n",
       " ('B002P3FQT0', 1370304000.0),\n",
       " ('B000VDCTCI', 1370736000.0),\n",
       " ('B000EOSHGQ', 1370736000.0),\n",
       " ('B0016ML7YE', 1370736000.0),\n",
       " ('B005XDASYC', 1370736000.0),\n",
       " ('B0095ZRQN0', 1379980800.0),\n",
       " ('B00CU9GKTO', 1382486400.0),\n",
       " ('B007G5NNOW', 1382659200.0),\n",
       " ('B005UEB5TQ', 1383523200.0),\n",
       " ('B007A4JTDI', 1390176000.0),\n",
       " ('B0045KGZOG', 1390176000.0),\n",
       " ('B005XUOQF2', 1390176000.0),\n",
       " ('B002JCSV8U', 1390176000.0),\n",
       " ('B003VTY2S8', 1390176000.0),\n",
       " ('B00005QIZ8', 1390176000.0),\n",
       " ('B0049WBZEK', 1392076800.0),\n",
       " ('B003OBUJIK', 1393113600.0),\n",
       " ('B007234F0O', 1393113600.0),\n",
       " ('B00FDPSH0W', 1395187200.0),\n",
       " ('B0037MH5W4', 1395878400.0),\n",
       " ('B00144KS6W', 1403740800.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history['A2C8I2RQ0WG940']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc2e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udict['A2C8I2RQ0WG940']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "547f0c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71628, 36145)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idict['B005UEB5TQ'], idict['B007A4JTDI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ff9048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A1C82BC5GNABOA', 1395273600.0),\n",
       " ('A23RMOGZKJJS6N', 1386720000.0),\n",
       " ('A2LDL960FST9LW', 1354060800.0),\n",
       " ('A2C8I2RQ0WG940', 1390176000.0),\n",
       " ('AV4XQWYQ3XLGD', 1369008000.0),\n",
       " ('A1QQKJU6TZKJUQ', 1333497600.0),\n",
       " ('A3U84V957MFKFC', 1368403200.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_history['B007A4JTDI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a96e1241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51424, 32273, 32682, 49237, 62539]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[udict[x[0]] for x in item_history['B007A4JTDI'] if x[1] < 1390176000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b305c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:azureml_py36_automl]",
   "language": "python",
   "name": "conda-env-azureml_py36_automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
