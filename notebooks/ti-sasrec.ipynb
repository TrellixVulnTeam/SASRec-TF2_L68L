{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Interval Based Transformer Model\n",
    "\n",
    "The original Transformer based recommender does not take into account of the time interval between two successive interactions. The paper Time Interval Aware Self-Attention for Sequential Recommendation, Jiacheng Li, Yujie Wang, Julian McAuley, WSDM, 2020 introduced the logic of including the time information. \n",
    "\n",
    "The original Git repo with TF 1.x is https://github.com/JiachengLi1995/TiSASRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "sys.path.insert(0, \"/recsys_data/RecSys/SASRec-tf2/\")\n",
    "\n",
    "import download_and_process_amazon as dpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/recsys_data/RecSys/SASRec-tf2/data\"\n",
    "meta_filename = 'meta_Electronics.json'\n",
    "encoded_file = \"ae_v3.txt\"\n",
    "\n",
    "# 5-core\n",
    "category = \"Electronics\"\n",
    "download_url = f\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_{category}_5.json.gz\"\n",
    "reviews_name = f\"reviews_{category}_5.json\"\n",
    "reviews_file = os.path.join(data_dir, reviews_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for ***Electronics***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/recsys_data/RecSys/SASRec-tf2/data/reviews_Electronics_5.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Generating data for ***{category}***\")\n",
    "dpa.download_and_extract(reviews_name, reviews_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reviews preprocessing...\n",
      "Processed data in /recsys_data/RecSys/SASRec-tf2/data/reviews_Electronics_5.json_output\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(reviews_file + '_output'):\n",
    "    reviews_output_file = dpa._reviews_preprocessing(reviews_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_with_time(fname, pname, K=3, sep=\"\\t\", file_write=False, add_time=False):\n",
    "    User = defaultdict(list)\n",
    "    Items = set()\n",
    "    user_dict, item_dict = {}, {}\n",
    "\n",
    "    with open(fname, 'r') as fr:\n",
    "        for line in fr:\n",
    "            u, i, t = line.rstrip().split(sep)\n",
    "            User[u].append((i, t))\n",
    "            Items.add(i)\n",
    "    \n",
    "    print(len(User), len(Items))\n",
    "    item_count = 1\n",
    "    for item in Items:\n",
    "        item_dict[item] = item_count\n",
    "        item_count += 1\n",
    "\n",
    "    count_del = 0\n",
    "    user_count = 1\n",
    "    if file_write:\n",
    "        print(f\"Writing data in {pname}\")\n",
    "        with open(pname, 'w') as fw:\n",
    "            for user in User.keys():\n",
    "                if len(User[user]) < K:\n",
    "#                     del User[user]\n",
    "                    count_del += 1\n",
    "                else:\n",
    "                    # user_dict[user] = user_count\n",
    "                    items = sorted(User[user], key=lambda x: x[1])\n",
    "                    timestamps = [x[1] for x in items]\n",
    "                    items = [item_dict[x[0]] for x in items]\n",
    "                    for i, t in zip(items, timestamps):\n",
    "                        out_txt = [str(user_count), str(i)]\n",
    "                        if add_time:\n",
    "                            out_txt.append(str(t))\n",
    "                        fw.write(sep.join(out_txt) + \"\\n\")\n",
    "                    user_dict[user] = user_count\n",
    "                    user_count += 1\n",
    "    else:\n",
    "        for user in User.keys():\n",
    "            if len(User[user]) < K:\n",
    "                # del User[user]\n",
    "                count_del += 1\n",
    "            else:\n",
    "                User[user] = sorted(User[user], key=lambda x: x[1])\n",
    "                user_dict[user] = user_count\n",
    "                user_count += 1\n",
    "        \n",
    "    print(user_count-1, count_del)\n",
    "    return user_dict, item_dict, User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 192403 users and 63001 items\n",
      "Total 192403 users and 63001 items\n",
      "Total 192403 users, 0 removed\n",
      "Processed model input data in /recsys_data/RecSys/SASRec-tf2/data/ae_v3.txt\n"
     ]
    }
   ],
   "source": [
    "udict, idict = dpa.data_process_with_time(reviews_output_file,\n",
    "                                      os.path.join(data_dir, encoded_file),\n",
    "                                      K=5,\n",
    "                                      sep=\"\\t\",\n",
    "                                      item_set=None,\n",
    "                                      add_time=True)\n",
    "len(udict), len(idict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 63161 users and 85930 items\n",
      "27773 items have less than 3 interactions\n",
      "47 users have less than 3 interactions\n",
      "Total 63114 users and 58157 items\n",
      "Total 63073 users, 41 removed\n",
      "Processed model input data in /recsys_data/RecSys/SASRec-tf2/data/ae_v3.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63073, 58157)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udict, idict = dpa.data_process_with_time(os.path.join(data_dir, \"ae_original.txt\"),\n",
    "                                          os.path.join(data_dir, encoded_file),\n",
    "                                          K=3,\n",
    "                                          sep=\"\\t\",\n",
    "                                          item_set=None,\n",
    "                                          add_time=True)\n",
    "len(udict), len(idict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63161 85930\n",
      "Writing data in /recsys_data/RecSys/SASRec-tf2/data/ae_v3.txt\n",
      "63114 47\n",
      "Retained 63114 users with 85930 items from 63161 users\n"
     ]
    }
   ],
   "source": [
    "udict, idict, user_history = data_process_with_time(os.path.join(data_dir, \"ae_original.txt\"),\n",
    "                                                    os.path.join(data_dir, encoded_file),\n",
    "                                                    K=3,\n",
    "                                                    sep=\"\\t\",\n",
    "                                                    file_write=True,\n",
    "                                                    add_time=True)\n",
    "print(f\"Retained {len(udict)} users with {len(idict)} items from {len(user_history)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "User = dpa.data_partition(os.path.join(data_dir, \"ae_v3.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[71865, 1276992000.0],\n",
       " [73699, 1295568000.0],\n",
       " [76752, 1305504000.0],\n",
       " [70038, 1339632000.0],\n",
       " [52031, 1369440000.0],\n",
       " [5655, 1370736000.0],\n",
       " [67712, 1370736000.0],\n",
       " [36497, 1382659200.0],\n",
       " [54084, 1390176000.0],\n",
       " [76563, 1390176000.0],\n",
       " [58972, 1390176000.0],\n",
       " [26213, 1390176000.0],\n",
       " [62645, 1390176000.0],\n",
       " [39023, 1392076800.0],\n",
       " [49569, 1393113600.0],\n",
       " [11443, 1395187200.0],\n",
       " [83584, 1395878400.0],\n",
       " [38275, 1403740800.0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Preparing done...\n"
     ]
    }
   ],
   "source": [
    "[user_train, user_valid, user_test, usernum, itemnum, timenum] = dpa.data_partition(os.path.join(data_dir, \"ae_v3.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33306, 1],\n",
       " [34165, 28],\n",
       " [35596, 42],\n",
       " [32497, 92],\n",
       " [24147, 135],\n",
       " [2640, 137],\n",
       " [31413, 137],\n",
       " [16854, 154],\n",
       " [25087, 165],\n",
       " [35505, 165],\n",
       " [27370, 165],\n",
       " [12196, 165],\n",
       " [29087, 165],\n",
       " [18026, 167],\n",
       " [23003, 169],\n",
       " [5337, 172]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18576000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1295568000 - 1276992000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features = 96, 6\n",
    "in1 = tf.keras.Input(shape=(n_timesteps, n_features))\n",
    "conv1 = tf.keras.layers.Conv1D(2, 2, strides=1)(in1)\n",
    "model = tf.keras.Model(inputs=in1, outputs=conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 6)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 95, 2)             26        \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1d_2/kernel:0' shape=(2, 6, 2) dtype=float32, numpy=\n",
       " array([[[ 0.27043295, -0.43187496],\n",
       "         [-0.473627  , -0.32877958],\n",
       "         [ 0.16233104, -0.05000722],\n",
       "         [ 0.26561534,  0.07231426],\n",
       "         [-0.18085214,  0.58943754],\n",
       "         [-0.39737538,  0.43327934]],\n",
       " \n",
       "        [[ 0.4520176 , -0.3670225 ],\n",
       "         [-0.45689282, -0.40269274],\n",
       "         [ 0.00142598, -0.28955248],\n",
       "         [ 0.33368218, -0.4050467 ],\n",
       "         [-0.28567907,  0.04187793],\n",
       "         [-0.04750389, -0.23195189]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - grad * lr\n",
    "grad = average(grad_i), i = 1.,, batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
