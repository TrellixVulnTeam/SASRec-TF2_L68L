{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85930"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/recsys_data/RecSys/SASRec-tf2/data/\"\n",
    "filename = \"ae_item_description.txt\"\n",
    "glove_dir = \"/recsys_data/datasets/glove\"\n",
    "maxlen = 100\n",
    "vocab_size = 5000\n",
    "embedding_dim = 50\n",
    "\n",
    "with open(os.path.join(data_dir, filename), 'r') as fr:\n",
    "    docs = fr.readlines()\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156986"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/64158898/what-does-keras-tokenizer-num-words-specify\n",
    "tokenizer = Tokenizer(num_words=5000, lower=True, split=' ', oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [k for k,v in tokenizer.word_index.items() if v <= vocab_size-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tokenizer.texts_to_sequences(docs)\n",
    "tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim, vocab_size):\n",
    "    # vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    all_words = set()\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            all_words.add(word)\n",
    "            if word in word_index:\n",
    "                idx = word_index.index(word)+1 \n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "    count_missing = len(set(word_index) - all_words)\n",
    "    if count_missing > 0:\n",
    "        print(f\"!!! {count_missing} words could not be mapped\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! 424 words could not be mapped\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = create_embedding_matrix(os.path.join(glove_dir, 'glove.6B.50d.txt'),\n",
    "                                           vocab,  \n",
    "                                           embedding_dim,\n",
    "                                           vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.27960005e-01, -8.47329974e-01,  1.39579999e+00,  1.67499995e+00,\n",
       "       -1.82579994e-01, -3.53850007e-01, -2.24559996e-02, -8.55679989e-01,\n",
       "       -3.85540009e-01,  1.28090000e+00,  9.04990017e-01,  2.61930004e-02,\n",
       "       -1.28050005e+00,  1.33340001e-01,  6.39569998e-01,  6.83510005e-01,\n",
       "       -1.68499994e+00,  7.39130020e-01, -1.72029994e-03, -5.89489996e-01,\n",
       "        1.01370001e+00,  2.40459993e-01, -6.40860021e-01, -2.84009993e-01,\n",
       "       -5.21189988e-01, -4.57659990e-01, -8.38559985e-01, -4.93090004e-01,\n",
       "       -9.24409986e-01, -9.25719976e-01,  1.99049997e+00,  2.03189999e-01,\n",
       "        1.05079997e+00,  3.07240009e-01, -1.42820001e-01, -6.85989976e-01,\n",
       "        1.83270007e-01, -3.46329987e-01, -3.81449997e-01, -1.66270006e+00,\n",
       "        3.12350005e-01, -6.63610026e-02, -2.49290004e-01, -5.20349979e-01,\n",
       "       -1.08900003e-01,  6.49280012e-01,  2.74949998e-01, -2.13450000e-01,\n",
       "       -1.27429998e+00,  2.87209988e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
